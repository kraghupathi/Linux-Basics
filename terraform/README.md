# What is Terraform?
- Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. 
- Terraform can manage existing and popular service providers as well as custom in-house solutions.
- Uses own syntax - HCL (Hashicorp Configuration Language) 
- Written in Golang.

# Why Terraform?
It gives the flexibility to begin with only knowledge of JSON operations, in place of many other tools that demand that you  learn a new script/language for their usage. Also, there aren’t any agent or client/server tools to run separately other than a single simple **.exe**. Terraform is simple and straightforward and supports OS, Cloud, etc. It is huge and still growing very fast.

# What is Infrastructure as code?
Infrastructure as code, or programmable infrastructure, means writing code (which can be done using a high level language or any descriptive language) to manage configurations and automate provisioning of infrastructure in addition to deployments. This is not simply writing scripts, but involves using tested and proven software development practices that are already being used in application development. 

For example: version control, testing, small deployments, use of design patterns etc. In short, this means you write code to provision and manage your server, in addition to automating processes.

It differs from infrastructure automation, which just involves replicating steps multiple times and reproducing them on several servers.

# Install Terraform
To install Terraform on any supported system:
- Find the appropriate [Terraform distribution package](https://www.terraform.io/downloads.html) for your system and download it. Terraform is distributed as a single __.zip__ file.
- After downloading Terraform, unzip the package to a directory of your choosing. Terraform runs as a single binary named **terraform**. Any other files in the package can be safely removed and Terraform will still function.
- Optional but recommended: modify the path to include the directory that contains the Terraform binary.

  [How to set the $PATH on Linux and Mac](https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux-unix)

  [How to set the PATH on Windows](https://stackoverflow.com/questions/1618280/where-can-i-set-path-to-make-exe-on-windows)

## Verifying the installation
After installing Terraform, verify the installation by opening a new terminal session and checking that Terraform is available. Execute **terraform** at the prompt, and you should see output

# Terraform Configuration
The set of files used to describe infrastructure in Terraform is known as a Terraform configuration.

Configuration files can be in either of two formats: HashiCorp Configuration Language (HCL), or JSON. HCL is a structured language created with DevOps in mind; it is machine-friendly yet easy for humans to read, and it supports comments. JSON is sometimes preferable when configurations are generated by a machine. A configuration can be composed of both .tf and .tf.json files

## Terraform modules
A typical Terraform module will have the following structure:

```
terraform
│
└───base-machine-module
│   │   main.tf
│   │   variables.tf
|   |   outputs.tf
│   
└───qa-env-module
│   │   main.tf
│   │   variables.tf
|   |   outputs.tf
```

## Providers
Terraform is used to create, manage, and update infrastructure resources such as physical machines, VMs, network switches, containers, and more. 

An example of a provider is AWS, which can manage resources of type aws_instance, aws_eip, aws_elb, etc.

Example of main.tf

```
provider "aws" {
 region = "eu-west-1"
 version = "~> 1.19"
 access_key = "${var.aws_access_key}"
 secret_key = "${var.aws_secret_key}"
}
```

## Resources
Resources are the most important things you'll configure in terraform. When you declare a resource, you are declaring a tangible component of your infrastructure.

Example of resources:

```
resource "aws_instance" "myapp_ec2_instance" {
 ami               = "ami-21f78e11"
 availability_zone = "${var.availability_zone}"
 instance_type     = "${var.instance_type}"

 tags {
   Name = "myapp-EC2-instance"
 }
}

resource "aws_ebs_volume" "myapp_ebs_volume" {
 availability_zone = "${var.availability_zone}"
 size              = 1

  tags {
   Name = "myapp-EBS-volume"
 }
}

resource "aws_volume_attachment" "myapp_vol_attachment" {
 device_name = "/dev/sdh"
 volume_id   = "${aws_ebs_volume.myapp_ebs_volume.id}"
 instance_id = "${aws_instance.myapp_ec2_instance.id}"
}
```

## Data Sources
Data allows you to query the provider API for information that you can then use to configure terraform resources

Example of Data sources

```
# Retrieves latest Amazon linux AMI
data "aws_ami" "aws_linux_ami" {
	most_recent = true

	filter {
		name = "name"
		values = ["amazon-ami-hvm-*-x86_64-gp2"]		
	}

	filter {
		name = "virtualization-type"
		values = ["hvm"]
	}
```

## Variables
Variables allow you to parameterise your terraform configurations. Allowing you to re-use the same code across multiple environments, with values passed to the config at runtime.

Variable declarations can be declared with default values, making them optional. Terraform will automatically detect the terraform.tfvars file if it exists, or you can pass another .tfvars file runtime (e.g qa.tfvars)

Example of variables:

```
# Required variables
variable "env"{}
variable "count"{}

# Variables with defaults

variable "instance_type" {
	default = "t2.micro"	
}

resource "aws_instance" "an_ec2_instance" {
	count = "${var.count}"
	ami   = "${data.aws_ami.aws_linux_ami_id}"
	instance_type = "${var.instance_type}"
}
```
Example of qa.tfvars

```
env = "qa"
count = "2"
```

## Output Variables
We can use output variables to organize data to be easily queried and shown back to the Terraform user.

While Terraform stores hundreds or thousands of attribute values for all our resources, we are more likely to be interested in a few values of importance, such as a load balancer IP, VPN address, etc.

Outputs are a way to tell Terraform what data is important. 

This data is outputted when **apply** is called, and can be queried using the **terraform output** command.

Example of defining outputs:

```
output "ip" {
  value = "${aws_eip.ip.public_ip}"
}
```

Viewing outputs:

Run **terraform apply** to populate the output. This only needs to be done once after the output is defined.

```
$ terraform apply
...

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

  ip = 13.17.232.222
```

apply highlights the outputs. You can also query the outputs after apply-time using **terraform output**:

```
$ terraform output ip
13.17.232.222
```

## Run Your First Terraform Operation

Terraform has five essential commands that allow us to deal with an end-to-end workflow:

- **terraform init:** This command is used to initialize a working directory containing Terraform configuration files.
- **terraform refresh:** This command is used to reconcile the state Terraform knows about (via its state file) with the real-world infrastructure.
- **terraform plan:** Creates an execution plan. Terraform performs a refresh, and then determines what actions are necessary to achieve the desired state specified in the configuration files.
- **terraform apply:** Apply the changes required to reach the desired state of the configuration.
- **terraform destroy:** destroys Terraform-managed infrastructure.

# Deploying ec2 instance with Terraform
Pre-requisite:
1. AWS account
2. EC2 Ubuntu instance.
3. Terraform installed
4. AWS CLI installed & configured

# Creating the project directory
In a location of your choice, create a directory named create-ec2-instance

Create the following directory structure (where the .tf files are blank text files):

```
create-ec2-instance/
    - providers.tf
    - main.tf
    - aws_ami.tf
    - variables.tf
    - .gitignore
```

**.gitignore**

Creating a Git repository with these files. If you do so, you should start with this **.gitignore** content:

```
# Compiled files
*.tfstate
*.tfstate.backup

# Module directory
.terraform/

# Sensitive Files
/variables.tf
```
Adding/variables.tf to your **.gitignore**  file because we're about to put some AWS secrets into it. Keeping the  secrets out of Github can keep them more secure and resistent to  accidents. In the future, your team may also want to use different  secrets to manage permissions to different resources.


**variables.tf**
Here is where we'll set some variables to be re-used by the rest of  the configuration. It will also serve as a handy place to keep our AWS  secrets.

Example of variables.tf:

```
# AWS Config

variable "aws_access_key" {
  default = "YOUR_ADMIN_ACCESS_KEY"
}

variable "aws_secret_key" {
  default = "YOUR_ADMIN_SECRET_KEY"
}

variable "aws_region" {
  default = "us-west-2"
}
```

Explanation of variables:

- **aws_access_key** - Access Key ID: that allows your machine to make calls to the AWS API.

- **aws_secret_key** - Secret Access Key that pairs with that Access Key ID

- **aws_region** - The region in which our infrastructure is hosted (I'm using  us-west-2 but you can change it if you'd like)


**providers.tf**

Example of providers.tf:

```
provider "aws" {
  access_key = "${var.aws_access_key}"
  secret_key = "${var.aws_secret_key}"
  region     = "${var.aws_region}"

  version = "~> 1.7"
}
```

**aws_ami.tf**

This file is dedicated to finding the right **Ubuntu AMI** to install on  our server. **AMI IDs** change from region to region and change over time as  upgrades come out.

Example of aws_ami.tf:

```
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["099720109477"] # Canonical
}
```

A data source is a read-only view into data stored  outside of Terraform. The data sources available will change based on  the provider. In this case, we are creating an aws_ami data source with the unique identifier of ubuntu.

The owners of the AMI that we're looking for (the official **Ubuntu AMI**), will always be Amazon. Therefore, the ID stored in owners is a constant.

We are using filter tags to filter all possible AMIs in the **AWS AMI** repository by name and **virtualization-type**.

Lastly, there will likely be multiple results when we apply all of these filters. most_recent  will select the most recent of the possible AMIs and return the  attributes of that for later use in our Terraform configuration.

**main.tf**

Example of main.tf:

```
resource "aws_instance" "test-instance" {
  ami             = "${data.aws_ami.ubuntu.id}"
  instance_type   = "t2.micro"

  tags {
    Name = "test-instance"
  }
}
```

Explanation:
1. We are defining an aws_instance with the unique Terraform identifier of my-test-instance
2. That instance should use the AMI found in aws_ami.tf to initialize the server
3. That instance should be a t2.micro (the cheapest AWS instance type)
4. We've attached a Name tag to the instance, test-instance, for easy identification

## Creating the Infrastructure
Navigate to the project's directory, and run the following:

```
$ terraform init
```
This will download and install the proper version of the AWS provider for your project and place it in a directory called .terraform.

```
$ terraform plan
```
This is exactly what we want, so run the apply command again and you’ll see your new EC2 Instance deploying

```
$ terraform apply
```
It will take the configurations we've  written and use the AWS API to build our servers. 

**Note:** You can type **yes** and hit **Enter** to create the new server.

Your infrastructure is build and check on your AWS console.

## Destroying the Infrastructure
When you’re done experimenting with Terraform, it’s a good idea to remove all the resources you created so AWS doesn’t charge you for them. Since Terraform keeps track of what resources you created, cleanup is a breeze. All you need to do is run the destroy command:

```
$ terraform destroy
```
You can type **yes** and hit **Enter.** 

Terraform will build the dependency graph and delete all the resources in the right order, using as much parallelism as possible. In about a minute, your AWS account should be clean again.


